#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸»è¦æŒ‡æ•°æ•°æ®è·å–å™¨
è·å–Aè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ä¸»è¦æŒ‡æ•°çš„å†å²æ•°æ®
"""


# ç½‘ç»œä¿®å¤è¡¥ä¸
import os
import requests
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# æ¸…é™¤ä»£ç†è®¾ç½®
for proxy_var in ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy']:
    if proxy_var in os.environ:
        del os.environ[proxy_var]

# ä¿®è¡¥requests
original_request = requests.Session.request
def patched_request(self, *args, **kwargs):
    kwargs.setdefault('proxies', {})
    kwargs.setdefault('verify', False)
    return original_request(self, *args, **kwargs)
requests.Session.request = patched_request

import akshare as ak
import pandas as pd
import numpy as np
import sqlite3
import os
import logging
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

class MajorIndexFetcher:
    def __init__(self, start_date="1990-01-01"):
        self.start_date = start_date
        self.output_dir = "output/index_data"
        self.db_path = os.path.join(self.output_dir, "major_indices.db")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.output_dir, exist_ok=True)
        
        # è®¾ç½®æ—¥å¿—
        self.setup_logging()
        
        # æŒ‡æ•°é…ç½®
        self.index_config = {
            # Aè‚¡ä¸»è¦æŒ‡æ•°
            "Aè‚¡æŒ‡æ•°": {
                "ä¸Šè¯æŒ‡æ•°": {"symbol": "000001", "source": "sina", "name": "ä¸Šè¯æŒ‡æ•°"},
                "æ·±è¯æˆæŒ‡": {"symbol": "399001", "source": "sina", "name": "æ·±è¯æˆæŒ‡"},
                "åˆ›ä¸šæ¿æŒ‡": {"symbol": "399006", "source": "sina", "name": "åˆ›ä¸šæ¿æŒ‡"},
                "ç§‘åˆ›50": {"symbol": "000688", "source": "sina", "name": "ç§‘åˆ›50"},
                "ä¸Šè¯50": {"symbol": "000016", "source": "sina", "name": "ä¸Šè¯50"},
                "æ²ªæ·±300": {"symbol": "000300", "source": "sina", "name": "æ²ªæ·±300"},
                "åŒ—è¯50": {"symbol": "899050", "source": "sina", "name": "åŒ—è¯50"},
            },
            # æ¸¯è‚¡æŒ‡æ•°
            "æ¸¯è‚¡æŒ‡æ•°": {
                "æ’ç”ŸæŒ‡æ•°": {"symbol": "HSI", "source": "investing", "name": "æ’ç”ŸæŒ‡æ•°"},
                "å›½ä¼æŒ‡æ•°": {"symbol": "HSCEI", "source": "investing", "name": "å›½ä¼æŒ‡æ•°"},
                "æ’ç”Ÿç§‘æŠ€æŒ‡æ•°": {"symbol": "HSTECH", "source": "investing", "name": "æ’ç”Ÿç§‘æŠ€æŒ‡æ•°"},
            },
            # ç¾è‚¡æŒ‡æ•°
            "ç¾è‚¡æŒ‡æ•°": {
                "é“ç¼æ–¯æŒ‡æ•°": {"symbol": "DJI", "source": "investing", "name": "é“ç¼æ–¯æŒ‡æ•°"},
                "çº³æ–¯è¾¾å…‹æŒ‡æ•°": {"symbol": "IXIC", "source": "investing", "name": "çº³æ–¯è¾¾å…‹æŒ‡æ•°"},
                "æ ‡æ™®500æŒ‡æ•°": {"symbol": "SPX", "source": "investing", "name": "æ ‡æ™®500æŒ‡æ•°"},
            }
        }
        
        self.downloaded_count = 0
        self.failed_count = 0
        self.failed_indices = []
        
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—é…ç½®"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('major_index_fetcher.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # åˆ›å»ºæŒ‡æ•°æ•°æ®è¡¨
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS index_data (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    index_name TEXT,
                    symbol TEXT,
                    market TEXT,
                    date TEXT,
                    open REAL,
                    high REAL,
                    low REAL,
                    close REAL,
                    volume INTEGER,
                    amount REAL,
                    UNIQUE(index_name, date)
                )
            ''')
            
            # åˆ›å»ºæŒ‡æ•°ä¿¡æ¯è¡¨
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS index_info (
                    index_name TEXT PRIMARY KEY,
                    symbol TEXT,
                    market TEXT,
                    last_update TEXT
                )
            ''')
            
            # åˆ›å»ºç´¢å¼•
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_index_date ON index_data(index_name, date)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_date ON index_data(date)')
            
            conn.commit()
            conn.close()
            
            self.logger.info(f"âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {self.db_path}")
            
        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise
    
    def get_a_share_index_data(self, symbol, index_name):
        """è·å–Aè‚¡æŒ‡æ•°æ•°æ®"""
        try:
            self.logger.info(f"æ­£åœ¨è·å– {index_name} ({symbol}) æ•°æ®...")
            
            # ä½¿ç”¨ä¸åŒçš„æ¥å£å°è¯•è·å–æ•°æ®ï¼Œä¼˜å…ˆä½¿ç”¨æ”¯æŒæŒ‡å®šæ—¥æœŸèŒƒå›´çš„å†å²æ•°æ®API
            df = None
            
            # æ–¹æ³•1: ä½¿ç”¨index_zh_a_histè·å–æŒ‡æ•°å†å²æ•°æ®ï¼ˆä¼˜å…ˆæ–¹æ³•ï¼Œæ”¯æŒæ—¥æœŸèŒƒå›´ï¼‰
            try:
                df = ak.index_zh_a_hist(
                    symbol=symbol,
                    period="daily", 
                    start_date=self.start_date.replace("-", ""),
                    end_date=datetime.now().strftime("%Y%m%d")
                )
                if df is not None and not df.empty:
                    self.logger.info(f"  æ–¹æ³•1æˆåŠŸ: ä½¿ç”¨index_zh_a_histè·å–åˆ° {len(df)} æ¡æ•°æ®")
                
            except Exception as e1:
                self.logger.warning(f"  æ–¹æ³•1å¤±è´¥: {str(e1)}")
                
                # æ–¹æ³•2: ä½¿ç”¨stock_zh_index_dailyè·å–æŒ‡æ•°æ•°æ®
                try:
                    if symbol.startswith('000'):  # ä¸Šäº¤æ‰€æŒ‡æ•°
                        df = ak.stock_zh_index_daily(symbol=f"sh{symbol}")
                    elif symbol.startswith('399'):  # æ·±äº¤æ‰€æŒ‡æ•°  
                        df = ak.stock_zh_index_daily(symbol=f"sz{symbol}")
                    elif symbol.startswith('899'):  # åŒ—äº¤æ‰€æŒ‡æ•°
                        df = ak.stock_zh_index_daily(symbol=f"bj{symbol}")
                    else:
                        df = ak.stock_zh_index_daily(symbol=symbol)
                        
                    if df is not None and not df.empty:
                        self.logger.info(f"  æ–¹æ³•2æˆåŠŸ: ä½¿ç”¨stock_zh_index_dailyè·å–åˆ° {len(df)} æ¡æ•°æ®")
                        
                except Exception as e2:
                    self.logger.warning(f"  æ–¹æ³•2å¤±è´¥: {str(e2)}")
                    
                    # æ–¹æ³•3: ä½¿ç”¨stock_zh_index_daily_em
                    try:
                        df = ak.stock_zh_index_daily_em(symbol=symbol)
                        if df is not None and not df.empty:
                            self.logger.info(f"  æ–¹æ³•3æˆåŠŸ: ä½¿ç”¨stock_zh_index_daily_emè·å–åˆ° {len(df)} æ¡æ•°æ®")
                    except Exception as e3:
                        self.logger.warning(f"  æ–¹æ³•3å¤±è´¥: {str(e3)}")
            
            if df is not None and not df.empty:
                # æ ‡å‡†åŒ–åˆ—å
                df = self.standardize_columns(df)
                
                # ç­›é€‰æ—¥æœŸèŒƒå›´
                start_date = datetime.strptime(self.start_date, "%Y-%m-%d")
                df['date'] = pd.to_datetime(df['date'])
                df = df[df['date'] >= start_date]
                
                # æŒ‰æ—¥æœŸæ’åº
                df = df.sort_values('date')
                
                self.logger.info(f"  âœ… {index_name}: è·å–åˆ° {len(df)} æ¡æ•°æ®")
                return df, "Aè‚¡æŒ‡æ•°"
            else:
                self.logger.error(f"  âŒ {index_name}: æœªè·å–åˆ°æ•°æ®")
                return None, None
                
        except Exception as e:
            self.logger.error(f"  âŒ {index_name}: è·å–å¤±è´¥ - {str(e)}")
            return None, None
    
    def get_hk_index_data(self, symbol, index_name):
        """è·å–æ¸¯è‚¡æŒ‡æ•°æ•°æ®"""
        try:
            self.logger.info(f"æ­£åœ¨è·å– {index_name} ({symbol}) æ•°æ®...")
            
            df = None
            
            # æ–¹æ³•1: ä½¿ç”¨index_investing_global
            try:
                # æ’ç”ŸæŒ‡æ•°ç³»åˆ—çš„æ˜ å°„
                hk_symbol_map = {
                    "HSI": "æ’ç”ŸæŒ‡æ•°",
                    "HSCEI": "æ’ç”Ÿå›½ä¼æŒ‡æ•°", 
                    "HSTECH": "æ’ç”Ÿç§‘æŠ€æŒ‡æ•°"
                }
                
                if symbol in hk_symbol_map:
                    df = ak.index_investing_global(
                        country="é¦™æ¸¯",
                        index=hk_symbol_map[symbol],
                        period="æ—¥çº¿",
                        start_date=self.start_date,
                        end_date=datetime.now().strftime("%Y-%m-%d")
                    )
                    
            except Exception as e1:
                self.logger.warning(f"  æ–¹æ³•1å¤±è´¥: {str(e1)}")
                
                # æ–¹æ³•2: ä½¿ç”¨stock_hk_index_daily_em
                try:
                    symbol_map = {
                        "HSI": "01", 
                        "HSCEI": "02",
                        "HSTECH": "03"
                    }
                    if symbol in symbol_map:
                        df = ak.stock_hk_index_daily_em(symbol=symbol_map[symbol])
                except Exception as e2:
                    self.logger.warning(f"  æ–¹æ³•2å¤±è´¥: {str(e2)}")
            
            if df is not None and not df.empty:
                # æ ‡å‡†åŒ–åˆ—å
                df = self.standardize_columns(df)
                
                # ç­›é€‰æ—¥æœŸèŒƒå›´
                start_date = datetime.strptime(self.start_date, "%Y-%m-%d")
                df['date'] = pd.to_datetime(df['date'])
                df = df[df['date'] >= start_date]
                
                # æŒ‰æ—¥æœŸæ’åº
                df = df.sort_values('date')
                
                self.logger.info(f"  âœ… {index_name}: è·å–åˆ° {len(df)} æ¡æ•°æ®")
                return df, "æ¸¯è‚¡æŒ‡æ•°"
            else:
                self.logger.error(f"  âŒ {index_name}: æœªè·å–åˆ°æ•°æ®")
                return None, None
                
        except Exception as e:
            self.logger.error(f"  âŒ {index_name}: è·å–å¤±è´¥ - {str(e)}")
            return None, None
    
    def get_us_index_data(self, symbol, index_name):
        """è·å–ç¾è‚¡æŒ‡æ•°æ•°æ®"""
        try:
            self.logger.info(f"æ­£åœ¨è·å– {index_name} ({symbol}) æ•°æ®...")
            
            df = None
            
            # æ–¹æ³•1: ä½¿ç”¨index_investing_global
            try:
                us_symbol_map = {
                    "DJI": "é“ç¼æ–¯å·¥ä¸šå¹³å‡æŒ‡æ•°",
                    "IXIC": "çº³æ–¯è¾¾å…‹ç»¼åˆæŒ‡æ•°",
                    "SPX": "æ ‡å‡†æ™®å°”500æŒ‡æ•°"
                }
                
                if symbol in us_symbol_map:
                    df = ak.index_investing_global(
                        country="ç¾å›½",
                        index=us_symbol_map[symbol],
                        period="æ—¥çº¿",
                        start_date=self.start_date,
                        end_date=datetime.now().strftime("%Y-%m-%d")
                    )
                    
            except Exception as e1:
                self.logger.warning(f"  æ–¹æ³•1å¤±è´¥: {str(e1)}")
                
                # æ–¹æ³•2: ä½¿ç”¨stock_us_index_daily
                try:
                    df = ak.stock_us_index_daily(symbol=symbol)
                except Exception as e2:
                    self.logger.warning(f"  æ–¹æ³•2å¤±è´¥: {str(e2)}")
            
            if df is not None and not df.empty:
                # æ ‡å‡†åŒ–åˆ—å
                df = self.standardize_columns(df)
                
                # ç­›é€‰æ—¥æœŸèŒƒå›´
                start_date = datetime.strptime(self.start_date, "%Y-%m-%d")
                df['date'] = pd.to_datetime(df['date'])
                df = df[df['date'] >= start_date]
                
                # æŒ‰æ—¥æœŸæ’åº
                df = df.sort_values('date')
                
                self.logger.info(f"  âœ… {index_name}: è·å–åˆ° {len(df)} æ¡æ•°æ®")
                return df, "ç¾è‚¡æŒ‡æ•°"
            else:
                self.logger.error(f"  âŒ {index_name}: æœªè·å–åˆ°æ•°æ®")
                return None, None
                
        except Exception as e:
            self.logger.error(f"  âŒ {index_name}: è·å–å¤±è´¥ - {str(e)}")
            return None, None
    
    def standardize_columns(self, df):
        """æ ‡å‡†åŒ–æ•°æ®åˆ—å"""
        # å¯èƒ½çš„åˆ—åæ˜ å°„
        column_mapping = {
            # æ—¥æœŸåˆ—
            'æ—¥æœŸ': 'date', 'Date': 'date', 'date': 'date', 'æ—¶é—´': 'date',
            # å¼€ç›˜ä»·åˆ—
            'å¼€ç›˜': 'open', 'å¼€ç›˜ä»·': 'open', 'Open': 'open', 'open': 'open',
            # æœ€é«˜ä»·åˆ—  
            'æœ€é«˜': 'high', 'æœ€é«˜ä»·': 'high', 'High': 'high', 'high': 'high',
            # æœ€ä½ä»·åˆ—
            'æœ€ä½': 'low', 'æœ€ä½ä»·': 'low', 'Low': 'low', 'low': 'low',
            # æ”¶ç›˜ä»·åˆ—
            'æ”¶ç›˜': 'close', 'æ”¶ç›˜ä»·': 'close', 'Close': 'close', 'close': 'close',
            # æˆäº¤é‡åˆ—
            'æˆäº¤é‡': 'volume', 'Volume': 'volume', 'volume': 'volume', 'vol': 'volume',
            # æˆäº¤é¢åˆ—
            'æˆäº¤é¢': 'amount', 'Amount': 'amount', 'amount': 'amount', 'æˆäº¤é‡‘é¢': 'amount'
        }
        
        # é‡å‘½ååˆ—
        df = df.rename(columns=column_mapping)
        
        # ç¡®ä¿å¿…éœ€çš„åˆ—å­˜åœ¨
        required_columns = ['date', 'open', 'high', 'low', 'close']
        for col in required_columns:
            if col not in df.columns:
                if col == 'date' and 'æ—¥æœŸ' in df.columns:
                    df['date'] = df['æ—¥æœŸ']
                elif col in ['open', 'high', 'low', 'close']:
                    # å¦‚æœç¼ºå°‘OHLCæ•°æ®ï¼Œè®¾ä¸ºæ”¶ç›˜ä»·
                    if 'close' in df.columns:
                        df[col] = df['close']
                    else:
                        df[col] = np.nan
        
        # è®¾ç½®é»˜è®¤å€¼
        if 'volume' not in df.columns:
            df['volume'] = 0
        if 'amount' not in df.columns:
            df['amount'] = 0.0
            
        return df
    
    def save_to_database(self, df, index_name, symbol, market):
        """ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            # å‡†å¤‡æ•°æ®
            df_copy = df.copy()
            df_copy['index_name'] = index_name
            df_copy['symbol'] = symbol
            df_copy['market'] = market
            df_copy['date'] = df_copy['date'].dt.strftime('%Y-%m-%d')
            
            # é€‰æ‹©éœ€è¦çš„åˆ—
            columns = ['index_name', 'symbol', 'market', 'date', 'open', 'high', 'low', 'close', 'volume', 'amount']
            df_save = df_copy[columns]
            
            # æ’å…¥æ•°æ®ï¼Œå¿½ç•¥é‡å¤
            df_save.to_sql('index_data', conn, if_exists='append', index=False)
            
            # æ›´æ–°æŒ‡æ•°ä¿¡æ¯
            cursor = conn.cursor()
            cursor.execute('''
                INSERT OR REPLACE INTO index_info (index_name, symbol, market, last_update)
                VALUES (?, ?, ?, ?)
            ''', (index_name, symbol, market, datetime.now().strftime('%Y-%m-%d %H:%M:%S')))
            
            conn.commit()
            conn.close()
            
            self.logger.info(f"  ğŸ’¾ {index_name}: å·²ä¿å­˜ {len(df_save)} æ¡è®°å½•åˆ°æ•°æ®åº“")
            return True
            
        except Exception as e:
            self.logger.error(f"  âŒ {index_name}: ä¿å­˜æ•°æ®åº“å¤±è´¥ - {str(e)}")
            return False
    
    def download_index_data(self, market_name, index_name, config):
        """ä¸‹è½½å•ä¸ªæŒ‡æ•°æ•°æ®"""
        symbol = config['symbol']
        
        try:
            # æ ¹æ®å¸‚åœºç±»å‹è°ƒç”¨ä¸åŒçš„è·å–å‡½æ•°
            if market_name == "Aè‚¡æŒ‡æ•°":
                df, market = self.get_a_share_index_data(symbol, index_name)
            elif market_name == "æ¸¯è‚¡æŒ‡æ•°":
                df, market = self.get_hk_index_data(symbol, index_name)
            elif market_name == "ç¾è‚¡æŒ‡æ•°":
                df, market = self.get_us_index_data(symbol, index_name)
            else:
                self.logger.error(f"âŒ æœªçŸ¥å¸‚åœºç±»å‹: {market_name}")
                return False
            
            if df is not None and market is not None:
                # ä¿å­˜åˆ°æ•°æ®åº“
                if self.save_to_database(df, index_name, symbol, market):
                    self.downloaded_count += 1
                    return True
            
            self.failed_count += 1
            self.failed_indices.append(f"{index_name} ({symbol})")
            return False
            
        except Exception as e:
            self.logger.error(f"âŒ {index_name}: ä¸‹è½½å¤±è´¥ - {str(e)}")
            self.failed_count += 1
            self.failed_indices.append(f"{index_name} ({symbol})")
            return False
    
    def download_all_indices(self):
        """ä¸‹è½½æ‰€æœ‰æŒ‡æ•°æ•°æ®"""
        self.logger.info("ğŸš€ å¼€å§‹ä¸‹è½½ä¸»è¦æŒ‡æ•°æ•°æ®...")
        self.logger.info("=" * 80)
        
        # åˆå§‹åŒ–æ•°æ®åº“
        self.init_database()
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_indices = sum(len(indices) for indices in self.index_config.values())
        self.logger.info(f"ğŸ“Š è®¡åˆ’ä¸‹è½½ {total_indices} ä¸ªæŒ‡æ•°çš„æ•°æ®")
        self.logger.info(f"ğŸ“… æ•°æ®æ—¶é—´èŒƒå›´: {self.start_date} è‡³ä»Š")
        self.logger.info("-" * 80)
        
        # é€ä¸ªå¸‚åœºä¸‹è½½
        for market_name, indices in self.index_config.items():
            self.logger.info(f"\nğŸ“ˆ æ­£åœ¨å¤„ç† {market_name} ({len(indices)}ä¸ªæŒ‡æ•°)")
            self.logger.info("-" * 50)
            
            for index_name, config in indices.items():
                self.download_index_data(market_name, index_name, config)
        
        # ç”Ÿæˆä¸‹è½½æŠ¥å‘Š
        self.generate_download_report()
        
    def generate_download_report(self):
        """ç”Ÿæˆä¸‹è½½æŠ¥å‘Š"""
        self.logger.info("\n" + "=" * 80)
        self.logger.info("ğŸ“‹ ä¸‹è½½å®Œæˆç»Ÿè®¡")
        self.logger.info("=" * 80)
        
        total_indices = sum(len(indices) for indices in self.index_config.values())
        
        self.logger.info(f"âœ… æˆåŠŸä¸‹è½½: {self.downloaded_count} ä¸ªæŒ‡æ•°")
        self.logger.info(f"âŒ ä¸‹è½½å¤±è´¥: {self.failed_count} ä¸ªæŒ‡æ•°")
        self.logger.info(f"ğŸ“Š æˆåŠŸç‡: {(self.downloaded_count/total_indices)*100:.1f}%")
        
        if self.failed_indices:
            self.logger.info("\nâŒ å¤±è´¥çš„æŒ‡æ•°:")
            for failed in self.failed_indices:
                self.logger.info(f"  - {failed}")
        
        # æ•°æ®åº“ç»Ÿè®¡
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ€»è®°å½•æ•°
            cursor.execute("SELECT COUNT(*) FROM index_data")
            total_records = cursor.fetchone()[0]
            
            # æŒ‰æŒ‡æ•°ç»Ÿè®¡
            cursor.execute("""
                SELECT index_name, COUNT(*) as record_count 
                FROM index_data 
                GROUP BY index_name 
                ORDER BY record_count DESC
            """)
            index_stats = cursor.fetchall()
            
            # æ—¥æœŸèŒƒå›´
            cursor.execute("SELECT MIN(date), MAX(date) FROM index_data")
            date_range = cursor.fetchone()
            
            conn.close()
            
            self.logger.info(f"\nğŸ’¾ æ•°æ®åº“ç»Ÿè®¡:")
            self.logger.info(f"  - æ€»è®°å½•æ•°: {total_records:,} æ¡")
            self.logger.info(f"  - æ•°æ®æ—¶é—´èŒƒå›´: {date_range[0]} è‡³ {date_range[1]}")
            self.logger.info(f"  - æ•°æ®åº“æ–‡ä»¶: {self.db_path}")
            
            if index_stats:
                self.logger.info(f"\nğŸ“Š å„æŒ‡æ•°æ•°æ®é‡:")
                for index_name, count in index_stats:
                    self.logger.info(f"  - {index_name}: {count:,} æ¡")
                    
        except Exception as e:
            self.logger.error(f"âŒ ç»Ÿè®¡æ•°æ®åº“ä¿¡æ¯å¤±è´¥: {str(e)}")
        
        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        self.save_report_to_file()
    
    def save_report_to_file(self):
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_file = os.path.join(self.output_dir, f"download_report_{timestamp}.txt")
            
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("ä¸»è¦æŒ‡æ•°æ•°æ®ä¸‹è½½æŠ¥å‘Š\n")
                f.write("=" * 50 + "\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                
                f.write("ğŸ“Š ä¸‹è½½ç»Ÿè®¡:\n")
                total_indices = sum(len(indices) for indices in self.index_config.values())
                f.write(f"  - è®¡åˆ’ä¸‹è½½: {total_indices} ä¸ªæŒ‡æ•°\n")
                f.write(f"  - æˆåŠŸä¸‹è½½: {self.downloaded_count} ä¸ªæŒ‡æ•°\n")
                f.write(f"  - ä¸‹è½½å¤±è´¥: {self.failed_count} ä¸ªæŒ‡æ•°\n")
                f.write(f"  - æˆåŠŸç‡: {(self.downloaded_count/total_indices)*100:.1f}%\n\n")
                
                f.write("ğŸ“ˆ æŒ‡æ•°åˆ—è¡¨:\n")
                for market_name, indices in self.index_config.items():
                    f.write(f"\n{market_name}:\n")
                    for index_name, config in indices.items():
                        status = "âœ…" if index_name not in [x.split(" (")[0] for x in self.failed_indices] else "âŒ"
                        f.write(f"  {status} {index_name} ({config['symbol']})\n")
                
                if self.failed_indices:
                    f.write(f"\nâŒ å¤±è´¥åˆ—è¡¨:\n")
                    for failed in self.failed_indices:
                        f.write(f"  - {failed}\n")
                
                f.write(f"\nğŸ’¾ æ•°æ®åº“æ–‡ä»¶: {self.db_path}\n")
                f.write(f"ğŸ“… æ•°æ®æ—¶é—´èŒƒå›´: {self.start_date} è‡³ä»Š\n")
            
            self.logger.info(f"ğŸ“„ ä¸‹è½½æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {str(e)}")
    
    def export_to_csv(self, split_by_index=True):
        """å¯¼å‡ºæ•°æ®ä¸ºCSVæ ¼å¼"""
        try:
            self.logger.info("\nğŸ“¤ å¼€å§‹å¯¼å‡ºCSVæ–‡ä»¶...")
            
            conn = sqlite3.connect(self.db_path)
            
            if split_by_index:
                # æŒ‰æŒ‡æ•°åˆ†åˆ«å¯¼å‡º
                csv_dir = os.path.join(self.output_dir, "csv_export")
                os.makedirs(csv_dir, exist_ok=True)
                
                # è·å–æ‰€æœ‰æŒ‡æ•°åˆ—è¡¨
                cursor = conn.cursor()
                cursor.execute("SELECT DISTINCT index_name FROM index_data")
                indices = [row[0] for row in cursor.fetchall()]
                
                for index_name in indices:
                    df = pd.read_sql(
                        "SELECT * FROM index_data WHERE index_name = ? ORDER BY date",
                        conn, params=(index_name,)
                    )
                    
                    filename = os.path.join(csv_dir, f"{index_name}.csv")
                    df.to_csv(filename, index=False, encoding='utf-8-sig')
                    self.logger.info(f"  âœ… {index_name}: {filename}")
                
                self.logger.info(f"ğŸ“ CSVæ–‡ä»¶å·²ä¿å­˜åˆ°: {csv_dir}")
                
            else:
                # å¯¼å‡ºåˆ°å•ä¸ªæ–‡ä»¶
                df = pd.read_sql("SELECT * FROM index_data ORDER BY index_name, date", conn)
                filename = os.path.join(self.output_dir, "all_indices_data.csv")
                df.to_csv(filename, index=False, encoding='utf-8-sig')
                self.logger.info(f"ğŸ“ æ‰€æœ‰æ•°æ®å·²ä¿å­˜åˆ°: {filename}")
            
            conn.close()
            
        except Exception as e:
            self.logger.error(f"âŒ å¯¼å‡ºCSVå¤±è´¥: {str(e)}")
    
    def query_index_data(self, index_name, start_date=None, end_date=None):
        """æŸ¥è¯¢æŒ‡å®šæŒ‡æ•°çš„æ•°æ®"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            sql = "SELECT * FROM index_data WHERE index_name = ?"
            params = [index_name]
            
            if start_date:
                sql += " AND date >= ?"
                params.append(start_date)
                
            if end_date:
                sql += " AND date <= ?"
                params.append(end_date)
            
            sql += " ORDER BY date"
            
            df = pd.read_sql(sql, conn, params=params)
            conn.close()
            
            return df
            
        except Exception as e:
            self.logger.error(f"âŒ æŸ¥è¯¢æ•°æ®å¤±è´¥: {str(e)}")
            return None

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ä¸»è¦æŒ‡æ•°æ•°æ®è·å–å·¥å…·")
    print("=" * 50)
    print("æ”¯æŒçš„æŒ‡æ•°:")
    print("  Aè‚¡: ä¸Šè¯æŒ‡æ•°ã€æ·±è¯æˆæŒ‡ã€åˆ›ä¸šæ¿æŒ‡ã€ç§‘åˆ›50ã€ä¸Šè¯50ã€æ²ªæ·±300ã€åŒ—è¯50")
    print("  æ¸¯è‚¡: æ’ç”ŸæŒ‡æ•°ã€å›½ä¼æŒ‡æ•°ã€æ’ç”Ÿç§‘æŠ€æŒ‡æ•°")
    print("  ç¾è‚¡: é“ç¼æ–¯æŒ‡æ•°ã€çº³æ–¯è¾¾å…‹æŒ‡æ•°ã€æ ‡æ™®500æŒ‡æ•°")
    print("=" * 50)
    
    # è·å–ç”¨æˆ·é…ç½®
    start_date = input("\nğŸ“… è¯·è¾“å…¥èµ·å§‹æ—¥æœŸ (æ ¼å¼: YYYY-MM-DD, é»˜è®¤: 2015-01-01): ").strip()
    if not start_date:
        start_date = "2015-01-01"
    
    # åˆ›å»ºè·å–å™¨
    fetcher = MajorIndexFetcher(start_date=start_date)
    
    try:
        # ä¸‹è½½æ‰€æœ‰æŒ‡æ•°æ•°æ®
        fetcher.download_all_indices()
        
        # è¯¢é—®æ˜¯å¦å¯¼å‡ºCSV
        export_csv = input("\nğŸ“¤ æ˜¯å¦å¯¼å‡ºä¸ºCSVæ–‡ä»¶ï¼Ÿ[y/n]: ").lower().strip()
        if export_csv == 'y':
            split_files = input("æ˜¯å¦æŒ‰æŒ‡æ•°åˆ†åˆ«å¯¼å‡ºï¼Ÿ[y/n]: ").lower().strip()
            fetcher.export_to_csv(split_by_index=(split_files == 'y'))
        
        print("\nğŸ‰ æŒ‡æ•°æ•°æ®è·å–å®Œæˆï¼")
        print(f"ğŸ’¾ æ•°æ®åº“æ–‡ä»¶: {fetcher.db_path}")
        print("ğŸ“Š å¯ä»¥ä½¿ç”¨å…¶ä»–å·¥å…·åˆ†æè¿™äº›æŒ‡æ•°æ•°æ®")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­ä¸‹è½½")
        print("ğŸ’¾ å·²ä¸‹è½½çš„æ•°æ®å·²ä¿å­˜")
    except Exception as e:
        print(f"\nâŒ ä¸‹è½½è¿‡ç¨‹å‡ºé”™: {e}")

if __name__ == "__main__":
    main()
