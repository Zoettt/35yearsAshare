#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Aè‚¡å†å²Kçº¿æ•°æ®è·å–å·¥å…·
ä»2015å¹´1æœˆå¼€å§‹è·å–æ‰€æœ‰Aè‚¡è‚¡ç¥¨çš„Kçº¿æ•°æ®
æ”¯æŒå¤šç§æ•°æ®æºå’Œæ‰¹é‡ä¸‹è½½
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import time
import logging
import os
import sys
from typing import List, Dict, Any, Optional, Tuple
import json
import pickle
from concurrent.futures import ThreadPoolExecutor, as_completed
import sqlite3

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config import LONGBRIDGE_CONFIG

# å®Œæ•´ç½‘ç»œä¿®å¤è¡¥ä¸
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# æ¸…é™¤ä»£ç†è®¾ç½®
proxy_vars = ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy', 'ALL_PROXY', 'all_proxy']
for var in proxy_vars:
    if var in os.environ:
        del os.environ[var]

os.environ['HTTP_PROXY'] = ''
os.environ['HTTPS_PROXY'] = ''
os.environ['NO_PROXY'] = '*'

# ä¿®è¡¥requests - æ›´å½»åº•çš„æ–¹å¼
import requests
original_request = requests.request
def patched_request(*args, **kwargs):
    kwargs['proxies'] = {}
    kwargs['verify'] = False
    kwargs['timeout'] = kwargs.get('timeout', 30)
    return original_request(*args, **kwargs)

requests.request = patched_request
requests.get = lambda *args, **kwargs: patched_request('GET', *args, **kwargs)
requests.post = lambda *args, **kwargs: patched_request('POST', *args, **kwargs)

try:
    import akshare as ak
except ImportError:
    print("è¯·å…ˆå®‰è£… akshare: pip install akshare")
    sys.exit(1)

try:
    import longbridge as lb
    from longbridge.openapi import QuoteContext, Config
    LONGBRIDGE_AVAILABLE = True
except ImportError:
    print("è­¦å‘Š: Longbridge SDK æœªå®‰è£…ï¼Œå°†ä»…ä½¿ç”¨ AKShare æ•°æ®æº")
    LONGBRIDGE_AVAILABLE = False

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('a_share_kline_fetcher.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class AShareKlineFetcher:
    """Aè‚¡Kçº¿æ•°æ®è·å–å™¨"""
    
    def __init__(self, start_date="2015-01-01", data_source="akshare"):
        """
        åˆå§‹åŒ–
        Args:
            start_date: æ•°æ®å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼: YYYY-MM-DD
            data_source: æ•°æ®æºï¼Œ"akshare" æˆ– "longbridge" æˆ– "both"
        """
        self.start_date = start_date
        self.data_source = data_source
        self.quote_ctx = None
        
        # æ•°æ®å­˜å‚¨ç›®å½•
        self.data_dir = "output/kline_data"
        os.makedirs(self.data_dir, exist_ok=True)
        
        # åˆ›å»ºSQLiteæ•°æ®åº“
        self.db_path = os.path.join(self.data_dir, "a_share_klines.db")
        self.init_database()
        
        # è¿›åº¦è¿½è¸ª
        self.progress_file = os.path.join(self.data_dir, "download_progress.json")
        self.progress = self.load_progress()
        
        # å¦‚æœé€‰æ‹©longbridgeæ•°æ®æºï¼Œåˆå§‹åŒ–API
        if data_source in ["longbridge", "both"] and LONGBRIDGE_AVAILABLE:
            self.init_longbridge_api()
        
        # Aè‚¡è‚¡ç¥¨ä»£ç ç”Ÿæˆè§„åˆ™
        self.stock_ranges = {
            "æ²ªå¸‚ä¸»æ¿": {
                "patterns": [
                    {"prefix": "600", "start": 600000, "end": 604000, "suffix": ".SH"},
                    {"prefix": "601", "start": 601000, "end": 602000, "suffix": ".SH"},
                    {"prefix": "603", "start": 603000, "end": 604000, "suffix": ".SH"},
                    {"prefix": "605", "start": 605000, "end": 606000, "suffix": ".SH"},
                ]
            },
            "ç§‘åˆ›æ¿": {
                "patterns": [
                    {"prefix": "688", "start": 688000, "end": 689000, "suffix": ".SH"}
                ]
            },
            "æ·±å¸‚ä¸»æ¿": {
                "patterns": [
                    {"prefix": "000", "start": 1, "end": 3000, "suffix": ".SZ"}
                ]
            },
            "ä¸­å°æ¿": {
                "patterns": [
                    {"prefix": "002", "start": 1, "end": 1000, "suffix": ".SZ"}
                ]
            },
            "åˆ›ä¸šæ¿": {
                "patterns": [
                    {"prefix": "300", "start": 300001, "end": 301000, "suffix": ".SZ"}
                ]
            }
        }
    
    def init_database(self):
        """åˆå§‹åŒ–SQLiteæ•°æ®åº“"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # åˆ›å»ºè‚¡ç¥¨ä¿¡æ¯è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS stock_info (
                    symbol TEXT PRIMARY KEY,
                    name TEXT,
                    market TEXT,
                    list_date TEXT,
                    last_update TEXT
                )
            """)
            
            # åˆ›å»ºKçº¿æ•°æ®è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS kline_data (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT,
                    date TEXT,
                    open REAL,
                    high REAL,
                    low REAL,
                    close REAL,
                    volume INTEGER,
                    amount REAL,
                    UNIQUE(symbol, date)
                )
            """)
            
            # åˆ›å»ºç´¢å¼•
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_symbol_date ON kline_data(symbol, date)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_date ON kline_data(date)")
            
            conn.commit()
            conn.close()
            logger.info("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def init_longbridge_api(self):
        """åˆå§‹åŒ–é•¿æ¡¥APIè¿æ¥"""
        try:
            config = Config(
                app_key=LONGBRIDGE_CONFIG["app_key"],
                app_secret=LONGBRIDGE_CONFIG["app_secret"],
                access_token=LONGBRIDGE_CONFIG["access_token"]
            )
            self.quote_ctx = QuoteContext(config)
            logger.info("é•¿æ¡¥APIè¿æ¥æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"é•¿æ¡¥APIè¿æ¥å¤±è´¥: {e}")
            return False
    
    def load_progress(self) -> Dict:
        """åŠ è½½ä¸‹è½½è¿›åº¦"""
        if os.path.exists(self.progress_file):
            try:
                with open(self.progress_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                pass
        return {"downloaded_symbols": [], "failed_symbols": [], "last_update": ""}
    
    def save_progress(self):
        """ä¿å­˜ä¸‹è½½è¿›åº¦"""
        try:
            self.progress["last_update"] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            with open(self.progress_file, 'w', encoding='utf-8') as f:
                json.dump(self.progress, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜è¿›åº¦å¤±è´¥: {e}")
    
    def generate_stock_symbols(self) -> List[str]:
        """ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„Aè‚¡è‚¡ç¥¨ä»£ç """
        symbols = []
        
        for market_name, market_config in self.stock_ranges.items():
            for pattern in market_config["patterns"]:
                prefix = pattern["prefix"]
                start = pattern["start"]
                end = pattern["end"]
                suffix = pattern["suffix"]
                
                if prefix == "000":  # æ·±å¸‚ä¸»æ¿ç‰¹æ®Šå¤„ç†
                    for i in range(start, end):
                        symbols.append(f"{i:06d}{suffix}")
                elif prefix == "002":  # ä¸­å°æ¿ç‰¹æ®Šå¤„ç†
                    for i in range(start, end):
                        symbols.append(f"00{i:04d}{suffix}")
                else:
                    for i in range(start, end):
                        symbols.append(f"{i:06d}{suffix}")
        
        logger.info(f"ç”Ÿæˆäº† {len(symbols)} ä¸ªæ½œåœ¨è‚¡ç¥¨ä»£ç ")
        return symbols
    
    def get_valid_stocks_akshare(self) -> List[Dict[str, str]]:
        """ä½¿ç”¨AKShareè·å–æœ‰æ•ˆè‚¡ç¥¨åˆ—è¡¨"""
        try:
            logger.info("æ­£åœ¨ä»AKShareè·å–Aè‚¡è‚¡ç¥¨åˆ—è¡¨...")
            
            # è·å–Aè‚¡è‚¡ç¥¨å®æ—¶æ•°æ®
            stock_list = ak.stock_zh_a_spot()
            
            if stock_list is None or stock_list.empty:
                logger.error("æœªèƒ½è·å–åˆ°è‚¡ç¥¨åˆ—è¡¨")
                return []
            
            valid_stocks = []
            for _, row in stock_list.iterrows():
                symbol = row.get('ä»£ç ', '')
                name = row.get('åç§°', '')
                
                if symbol and name:
                    # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç æ ¼å¼
                    if len(symbol) == 6 and symbol.isdigit():
                        if symbol.startswith(('000', '001', '002', '003', '300')):
                            symbol += '.SZ'
                        elif symbol.startswith(('600', '601', '603', '605', '688')):
                            symbol += '.SH'
                    
                    valid_stocks.append({
                        'symbol': symbol,
                        'name': name,
                        'market': self.get_market_type(symbol)
                    })
            
            logger.info(f"è·å–åˆ° {len(valid_stocks)} åªæœ‰æ•ˆè‚¡ç¥¨")
            return valid_stocks
            
        except Exception as e:
            logger.error(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def get_market_type(self, symbol: str) -> str:
        """åˆ¤æ–­è‚¡ç¥¨æ‰€å±å¸‚åœº"""
        code = symbol[:6]
        if symbol.endswith('.SH'):
            if code.startswith(('600', '601', '603', '605')):
                return 'æ²ªå¸‚ä¸»æ¿'
            elif code.startswith('688'):
                return 'ç§‘åˆ›æ¿'
            else:
                return 'æ²ªå¸‚å…¶ä»–'
        elif symbol.endswith('.SZ'):
            if code.startswith('000'):
                return 'æ·±å¸‚ä¸»æ¿'
            elif code.startswith('002'):
                return 'ä¸­å°æ¿'
            elif code.startswith('300'):
                return 'åˆ›ä¸šæ¿'
            else:
                return 'æ·±å¸‚å…¶ä»–'
        return 'æœªçŸ¥å¸‚åœº'
    
    def get_kline_data_akshare(self, symbol: str, start_date: str = None) -> Optional[pd.DataFrame]:
        """ä½¿ç”¨AKShareè·å–å•åªè‚¡ç¥¨çš„Kçº¿æ•°æ®"""
        try:
            if start_date is None:
                start_date = self.start_date
            
            # ä¸ºAKShareæ·»åŠ å¸‚åœºå‰ç¼€ï¼Œå¤„ç†è‚¡ç¥¨ä»£ç æ ¼å¼
            stock_code = symbol.split('.')[0]  # å»æ‰åç¼€
            
            if symbol.startswith('bj'):
                # åŒ—äº¤æ‰€è‚¡ç¥¨ï¼Œä½¿ç”¨åŸä»£ç 
                ak_symbol = stock_code
            elif symbol.startswith('sh'):
                # å·²å¸¦shå‰ç¼€çš„ä¸Šæµ·è‚¡ç¥¨
                ak_symbol = stock_code
            elif symbol.startswith('sz'):
                # å·²å¸¦szå‰ç¼€çš„æ·±åœ³è‚¡ç¥¨
                ak_symbol = stock_code
            elif stock_code.startswith('6'):
                # ä¸Šæµ·è‚¡ç¥¨ï¼ˆ6å¼€å¤´ï¼‰
                ak_symbol = 'sh' + stock_code
            else:
                # æ·±åœ³è‚¡ç¥¨ï¼ˆ0ã€3å¼€å¤´ç­‰ï¼‰
                ak_symbol = 'sz' + stock_code
            
            # è½¬æ¢æ—¥æœŸæ ¼å¼
            start_str = start_date.replace('-', '')
            end_str = datetime.now().strftime('%Y%m%d')
            
            logger.debug(f"æ­£åœ¨è·å– {symbol} (akshare: {ak_symbol}) ä» {start_date} çš„Kçº¿æ•°æ®...")
            
            # ä½¿ç”¨AKShareè·å–å†å²æ•°æ® - ä½¿ç”¨stock_zh_a_dailyï¼ˆç¨³å®šå¯ç”¨ï¼‰
            df = ak.stock_zh_a_daily(
                symbol=ak_symbol,
                start_date=start_str,
                end_date=end_str,
                adjust="qfq"  # å‰å¤æƒ
            )
            
            if df is None or df.empty:
                return None
            
            # æ ‡å‡†åŒ–åˆ—å
            df = df.rename(columns={
                'æ—¥æœŸ': 'date',
                'å¼€ç›˜': 'open',
                'æœ€é«˜': 'high', 
                'æœ€ä½': 'low',
                'æ”¶ç›˜': 'close',
                'æˆäº¤é‡': 'volume',
                'æˆäº¤é¢': 'amount'
            })
            
            # æ·»åŠ è‚¡ç¥¨ä»£ç åˆ—
            df['symbol'] = symbol
            
            # ç¡®ä¿æ—¥æœŸæ ¼å¼
            df['date'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d')
            
            # è¿‡æ»¤æŒ‡å®šæ—¥æœŸä¹‹åçš„æ•°æ®
            df = df[df['date'] >= start_date]
            
            logger.debug(f"æˆåŠŸè·å– {symbol} æ•°æ® {len(df)} æ¡")
            return df
            
        except Exception as e:
            logger.debug(f"è·å– {symbol} Kçº¿æ•°æ®å¤±è´¥: {e}")
            return None
    
    def save_kline_to_db(self, df: pd.DataFrame):
        """ä¿å­˜Kçº¿æ•°æ®åˆ°æ•°æ®åº“"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            # ä½¿ç”¨INSERT OR REPLACEé¿å…é‡å¤æ•°æ®
            for _, row in df.iterrows():
                conn.execute("""
                    INSERT OR REPLACE INTO kline_data 
                    (symbol, date, open, high, low, close, volume, amount)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    row['symbol'], row['date'], row['open'], row['high'],
                    row['low'], row['close'], row['volume'], row['amount']
                ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“å¤±è´¥: {e}")
    
    def save_stock_info_to_db(self, stocks_info: List[Dict[str, str]]):
        """ä¿å­˜è‚¡ç¥¨ä¿¡æ¯åˆ°æ•°æ®åº“"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            for stock in stocks_info:
                conn.execute("""
                    INSERT OR REPLACE INTO stock_info 
                    (symbol, name, market, last_update)
                    VALUES (?, ?, ?, ?)
                """, (
                    stock['symbol'], stock['name'], stock['market'],
                    datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"ä¿å­˜è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}")
    
    def download_single_stock(self, stock_info: Dict[str, str]) -> bool:
        """ä¸‹è½½å•åªè‚¡ç¥¨çš„Kçº¿æ•°æ®"""
        symbol = stock_info['symbol']
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»ä¸‹è½½è¿‡
        if symbol in self.progress.get('downloaded_symbols', []):
            logger.debug(f"{symbol} å·²ä¸‹è½½ï¼Œè·³è¿‡")
            return True
        
        try:
            # è·å–Kçº¿æ•°æ®ï¼Œä¼ é€’æ­£ç¡®çš„èµ·å§‹æ—¥æœŸ
            df = self.get_kline_data_akshare(symbol, self.start_date)
            
            if df is not None and not df.empty:
                # ä¿å­˜åˆ°æ•°æ®åº“
                self.save_kline_to_db(df)
                
                # æ›´æ–°è¿›åº¦
                if 'downloaded_symbols' not in self.progress:
                    self.progress['downloaded_symbols'] = []
                self.progress['downloaded_symbols'].append(symbol)
                
                logger.info(f"âœ… {symbol} ({stock_info['name']}) ä¸‹è½½å®Œæˆï¼Œå…± {len(df)} æ¡æ•°æ®")
                return True
            else:
                logger.warning(f"âŒ {symbol} ({stock_info['name']}) æ— æ•°æ®")
                if 'failed_symbols' not in self.progress:
                    self.progress['failed_symbols'] = []
                self.progress['failed_symbols'].append(symbol)
                return False
                
        except Exception as e:
            logger.error(f"âŒ {symbol} ({stock_info['name']}) ä¸‹è½½å¤±è´¥: {e}")
            if 'failed_symbols' not in self.progress:
                self.progress['failed_symbols'] = []
            self.progress['failed_symbols'].append(symbol)
            return False
    
    def download_all_stocks(self, max_workers: int = 5, batch_size: int = 50):
        """ä¸‹è½½æ‰€æœ‰è‚¡ç¥¨çš„Kçº¿æ•°æ®"""
        logger.info(f"å¼€å§‹ä¸‹è½½Aè‚¡Kçº¿æ•°æ®ï¼Œä» {self.start_date} å¼€å§‹...")
        
        # è·å–æœ‰æ•ˆè‚¡ç¥¨åˆ—è¡¨
        valid_stocks = self.get_valid_stocks_akshare()
        if not valid_stocks:
            logger.error("æœªèƒ½è·å–æœ‰æ•ˆè‚¡ç¥¨åˆ—è¡¨ï¼Œé€€å‡º")
            return
        
        # ä¿å­˜è‚¡ç¥¨ä¿¡æ¯åˆ°æ•°æ®åº“
        self.save_stock_info_to_db(valid_stocks)
        
        total_stocks = len(valid_stocks)
        logger.info(f"å…±éœ€ä¸‹è½½ {total_stocks} åªè‚¡ç¥¨çš„æ•°æ®")
        
        # æŒ‰æ‰¹æ¬¡å¤„ç†
        for i in range(0, total_stocks, batch_size):
            batch_stocks = valid_stocks[i:i + batch_size]
            batch_num = i // batch_size + 1
            total_batches = (total_stocks + batch_size - 1) // batch_size
            
            logger.info(f"å¤„ç†ç¬¬ {batch_num}/{total_batches} æ‰¹ï¼Œè‚¡ç¥¨æ•°: {len(batch_stocks)}")
            
            # ä½¿ç”¨çº¿ç¨‹æ± ä¸‹è½½
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = [executor.submit(self.download_single_stock, stock) 
                          for stock in batch_stocks]
                
                completed = 0
                for future in as_completed(futures):
                    completed += 1
                    if completed % 10 == 0:
                        logger.info(f"  æ‰¹æ¬¡è¿›åº¦: {completed}/{len(batch_stocks)}")
            
            # æ¯æ‰¹æ¬¡åä¿å­˜è¿›åº¦
            self.save_progress()
            
            # æ·»åŠ å»¶è¿Ÿï¼Œé¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
            time.sleep(2)
        
        logger.info("æ‰€æœ‰è‚¡ç¥¨æ•°æ®ä¸‹è½½å®Œæˆï¼")
        self.generate_summary_report()
    
    def generate_summary_report(self):
        """ç”Ÿæˆä¸‹è½½æ±‡æ€»æŠ¥å‘Š"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            # ç»Ÿè®¡æ•°æ®
            cursor = conn.cursor()
            
            # è‚¡ç¥¨æ•°é‡ç»Ÿè®¡
            cursor.execute("SELECT COUNT(DISTINCT symbol) FROM kline_data")
            total_stocks = cursor.fetchone()[0]
            
            # æ€»è®°å½•æ•°
            cursor.execute("SELECT COUNT(*) FROM kline_data") 
            total_records = cursor.fetchone()[0]
            
            # æ—¥æœŸèŒƒå›´
            cursor.execute("SELECT MIN(date), MAX(date) FROM kline_data")
            date_range = cursor.fetchone()
            
            # æŒ‰å¸‚åœºç»Ÿè®¡
            cursor.execute("""
                SELECT s.market, COUNT(DISTINCT k.symbol) 
                FROM stock_info s 
                JOIN kline_data k ON s.symbol = k.symbol 
                GROUP BY s.market
            """)
            market_stats = cursor.fetchall()
            
            conn.close()
            
            # ç”ŸæˆæŠ¥å‘Š
            report = f"""
=== Aè‚¡Kçº¿æ•°æ®ä¸‹è½½æ±‡æ€»æŠ¥å‘Š ===
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ“Š æ•°æ®ç»Ÿè®¡:
  - è‚¡ç¥¨æ€»æ•°: {total_stocks} åª
  - æ•°æ®è®°å½•æ€»æ•°: {total_records:,} æ¡
  - æ•°æ®æ—¥æœŸèŒƒå›´: {date_range[0]} è‡³ {date_range[1]}
  - å¹³å‡æ¯åªè‚¡ç¥¨: {total_records//max(total_stocks,1):,} æ¡è®°å½•

ğŸ“ˆ å¸‚åœºåˆ†å¸ƒ:
"""
            for market, count in market_stats:
                report += f"  - {market}: {count} åªè‚¡ç¥¨\n"
            
            report += f"""
ğŸ’¾ æ•°æ®å­˜å‚¨:
  - æ•°æ®åº“æ–‡ä»¶: {self.db_path}
  - æ–‡ä»¶å¤§å°: {os.path.getsize(self.db_path)/1024/1024:.2f} MB

âœ… ä¸‹è½½æˆåŠŸ: {len(self.progress.get('downloaded_symbols', []))} åª
âŒ ä¸‹è½½å¤±è´¥: {len(self.progress.get('failed_symbols', []))} åª

=== æŠ¥å‘Šç»“æŸ ===
"""
            
            # ä¿å­˜æŠ¥å‘Š
            report_file = os.path.join(self.data_dir, f"download_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt")
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            
            print(report)
            logger.info(f"æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ±‡æ€»æŠ¥å‘Šå¤±è´¥: {e}")
    
    def export_to_csv(self, output_dir: str = None, split_by_symbol: bool = False):
        """å¯¼å‡ºæ•°æ®åˆ°CSVæ–‡ä»¶"""
        if output_dir is None:
            output_dir = os.path.join(self.data_dir, "csv_export")
        
        os.makedirs(output_dir, exist_ok=True)
        
        try:
            conn = sqlite3.connect(self.db_path)
            
            if split_by_symbol:
                # æŒ‰è‚¡ç¥¨åˆ†åˆ«å¯¼å‡º
                cursor = conn.cursor()
                cursor.execute("SELECT DISTINCT symbol FROM kline_data ORDER BY symbol")
                symbols = [row[0] for row in cursor.fetchall()]
                
                logger.info(f"å¼€å§‹å¯¼å‡º {len(symbols)} åªè‚¡ç¥¨çš„CSVæ–‡ä»¶...")
                
                for i, symbol in enumerate(symbols):
                    if i % 100 == 0:
                        logger.info(f"å¯¼å‡ºè¿›åº¦: {i}/{len(symbols)}")
                    
                    df = pd.read_sql_query(
                        "SELECT * FROM kline_data WHERE symbol = ? ORDER BY date",
                        conn, params=(symbol,)
                    )
                    
                    # æ¸…ç†æ–‡ä»¶åä¸­çš„ç‰¹æ®Šå­—ç¬¦
                    safe_symbol = symbol.replace('.', '_')
                    filename = os.path.join(output_dir, f"{safe_symbol}.csv")
                    df.to_csv(filename, index=False, encoding='utf-8-sig')
                
                logger.info(f"CSVæ–‡ä»¶å¯¼å‡ºå®Œæˆï¼Œä¿å­˜åœ¨: {output_dir}")
            else:
                # å¯¼å‡ºå…¨éƒ¨æ•°æ®åˆ°å•ä¸ªæ–‡ä»¶
                logger.info("å¯¼å‡ºå…¨éƒ¨æ•°æ®åˆ°å•ä¸ªCSVæ–‡ä»¶...")
                df = pd.read_sql_query(
                    "SELECT * FROM kline_data ORDER BY symbol, date",
                    conn
                )
                
                filename = os.path.join(output_dir, f"all_a_share_klines_{datetime.now().strftime('%Y%m%d')}.csv")
                df.to_csv(filename, index=False, encoding='utf-8-sig')
                
                logger.info(f"CSVæ–‡ä»¶å·²ä¿å­˜åˆ°: {filename}")
            
            conn.close()
            
        except Exception as e:
            logger.error(f"å¯¼å‡ºCSVæ–‡ä»¶å¤±è´¥: {e}")
    
    def query_stock_data(self, symbol: str, start_date: str = None, end_date: str = None) -> pd.DataFrame:
        """æŸ¥è¯¢æŒ‡å®šè‚¡ç¥¨çš„Kçº¿æ•°æ®"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            query = "SELECT * FROM kline_data WHERE symbol = ?"
            params = [symbol]
            
            if start_date:
                query += " AND date >= ?"
                params.append(start_date)
            
            if end_date:
                query += " AND date <= ?"
                params.append(end_date)
            
            query += " ORDER BY date"
            
            df = pd.read_sql_query(query, conn, params=params)
            conn.close()
            
            return df
            
        except Exception as e:
            logger.error(f"æŸ¥è¯¢è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Aè‚¡å†å²Kçº¿æ•°æ®è·å–å·¥å…·")
    print("=" * 50)
    
    # é…ç½®å‚æ•°
    start_date = "2015-01-01"  # èµ·å§‹æ—¥æœŸ
    max_workers = 3  # å¹¶å‘ä¸‹è½½çº¿ç¨‹æ•°
    batch_size = 50  # æ‰¹æ¬¡å¤§å°
    
    print(f"ğŸ“… æ•°æ®èµ·å§‹æ—¥æœŸ: {start_date}")
    print(f"ğŸ”„ å¹¶å‘çº¿ç¨‹æ•°: {max_workers}")
    print(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {batch_size}")
    print("=" * 50)
    
    # åˆ›å»ºæ•°æ®è·å–å™¨
    fetcher = AShareKlineFetcher(start_date=start_date)
    
    # å¼€å§‹ä¸‹è½½
    try:
        fetcher.download_all_stocks(max_workers=max_workers, batch_size=batch_size)
        
        print("\nğŸ‰ æ•°æ®ä¸‹è½½å®Œæˆï¼")
        print(f"ğŸ“ æ•°æ®åº“æ–‡ä»¶: {fetcher.db_path}")
        
        # è¯¢é—®æ˜¯å¦å¯¼å‡ºCSV
        export_choice = input("\næ˜¯å¦å¯¼å‡ºä¸ºCSVæ–‡ä»¶ï¼Ÿ(y/n): ").lower().strip()
        if export_choice == 'y':
            split_choice = input("æ˜¯å¦æŒ‰è‚¡ç¥¨åˆ†åˆ«å¯¼å‡ºï¼Ÿ(y/n): ").lower().strip()
            fetcher.export_to_csv(split_by_symbol=(split_choice == 'y'))
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­ä¸‹è½½")
        fetcher.save_progress()
        print("è¿›åº¦å·²ä¿å­˜ï¼Œå¯ä»¥ç¨åç»§ç»­")
    except Exception as e:
        logger.error(f"ä¸‹è½½è¿‡ç¨‹å‡ºé”™: {e}")
        fetcher.save_progress()

if __name__ == "__main__":
    main()
